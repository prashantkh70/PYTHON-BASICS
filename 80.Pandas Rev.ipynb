{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81468a28",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ef63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ced838",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two data Structure:\n",
    "    1. Series >> 1D\n",
    "    2. DatFrame >> 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32e2c0",
   "metadata": {},
   "source": [
    "# Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4544770",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. list\n",
    "2. tuple\n",
    "3. numpy array\n",
    "4. series\n",
    "5. dictionary\n",
    "6. csv\n",
    "7. excel\n",
    "8. JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d25fb",
   "metadata": {},
   "source": [
    "# Access Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_name'] #series\n",
    "df[col_list]\n",
    "\n",
    "\n",
    "iloc:\n",
    "    df.iloc[row_index,col_index]\n",
    "    df.iloc[row_index_list,col_index_list]\n",
    "    df.iloc[2:10:2,2:4]\n",
    "    df.iloc[2:10,2,5]\n",
    "    \n",
    "    \n",
    "loc:\n",
    "    df.loc[row_label,col_label]\n",
    "    df.loc[row_label_list,col_label_list]\n",
    "    \n",
    "df.head()# default first 5 rows\n",
    "df.tail() # default last 5 rows\n",
    "df.head(10)#  first 10 rows\n",
    "df.tail(15) # last 15 rows\n",
    "df.columns  #column list\n",
    "df.index  # row list\n",
    "df.axes   # both\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b812e",
   "metadata": {},
   "source": [
    "## Access rows and columns by using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. df.iterrows()  # access rows iteration >> row_name ,data\n",
    "2. df.items()  # columns  >>> col_name,data\n",
    "3. df.iteritems() # columns  >>> col_name,data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e97e19",
   "metadata": {},
   "source": [
    "# All information about DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. df.shape  #(rows, columns)\n",
    "    df.shape[0] >> rows\n",
    "    df.shape[1] >> col\n",
    "2. df.dtypes\n",
    "3. df.select_dtypes()\n",
    "4. df.info()\n",
    "5. df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b522d3",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d89a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Detect missing values:\n",
    "    1. df.isna()\n",
    "    2. df.isnull()\n",
    "    3. df.isna().sum()\n",
    "    4. df.isnull().sum()\n",
    "    5. df.isna().mean()*100\n",
    "    6. df.isnull().mean()*100\n",
    "    \n",
    "2. Drop Null Values:\n",
    "    1. df.dropna(axis=0,thresh)\n",
    "    2. df.dropna(axis=1,thresh)\n",
    "    3. df.drop('col_name',axis=1,inplace=True)\n",
    "    4. df.drop('row_name', axis=0)\n",
    "    \n",
    "3. Fill missing value:\n",
    "    1. df.fillna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42c10c",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series:\n",
    "    1. df['col_name'].mean()\n",
    "    2. df['col_name'].median()\n",
    "    3. df['col_name'].mode()[0]\n",
    "    4. df['col_name'].std()\n",
    "    5. df['col_name'].var()\n",
    "    6. df['col_name'].max()\n",
    "    7. df['col_name'].min()\n",
    "    8. df['col_name'].quantile(0.25)\n",
    "    9. df['col_name'].quantile(0.5)\n",
    "    10. df['col_name'].quantile(0.75)\n",
    "    \n",
    "DataFrame:\n",
    "    1.df.mean()\n",
    "    2.df.median()\n",
    "    3. df.mode()[0]\n",
    "    4. df.std()\n",
    "    5. df.var()\n",
    "    6. df.min()\n",
    "    7. df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5f5a1",
   "metadata": {},
   "source": [
    "# sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458aeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. df.sort_index()\n",
    "2. df.sort_values()\n",
    "3. df.set_index()\n",
    "4. df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358513f3",
   "metadata": {},
   "source": [
    "# Pandas other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d919bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. df['col_name'].unique()\n",
    "2. df['col_name'].nunique()\n",
    "3. df['col_name'].value_counts()\n",
    "4. pd.crosstab(df[col1],df[col2])\n",
    "5. rename:\n",
    "    df.rename(dict,axis=0,inplace=True)\n",
    "    df.rename(dict,axis=1,inplace=True)\n",
    "6. replace:\n",
    "    df.replace(dictionary)\n",
    "    df['col_name'].replace(dict)\n",
    "    \n",
    "7. df.insert(col_index,col_name,values) #values >> list tuple series array\n",
    "8. df.drop_duplicates()\n",
    "9. groupby:\n",
    "    1. df.groupby.groups()\n",
    "    2. df.groupby.groups.keys()\n",
    "    3. df.groupby.first()\n",
    "    4. df.groupby('col_name').get_group('value')\n",
    "    5. df.groupby(['col_1','col2']).get_group(('value1','value2'))\n",
    "    \n",
    "10. apply:\n",
    "    df.apply(function_name)\n",
    "    df['col'].apply(fun_name)\n",
    "11. pd.get_dummies()  #one vs other  # one hot encoding\n",
    "\n",
    "12. Dataframe to:\n",
    "    1. df.to_numpy()\n",
    "    2. df.values\n",
    "    3. df.to_numpy().tolist()\n",
    "    4. df.values.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca74c0",
   "metadata": {},
   "source": [
    "# loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. df.loc[condition]\n",
    "2. df.loc[df['col1']==100]\n",
    "3. df.loc[df['col1']==100\n",
    "         & df.loc[df['col1']==200]]\n",
    "\n",
    "3. df.loc[df['col'].isin(list)]\n",
    "4. df.loc[df['col'].isin(list)] |df.loc[df['col'].isin(list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590dc65",
   "metadata": {},
   "source": [
    "# Read and Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. readdata:\n",
    "    1. pd.read_csv\n",
    "    2. pd.read_excel\n",
    "    3. pd.read_json\n",
    "    \n",
    "2. Write:\n",
    "    1. df.to_csv\n",
    "    2. df.to_excel()\n",
    "    3. df.to_dict\n",
    "    4. df.to_json\n",
    "    \n",
    "3. write excel file with multiple sheet:\n",
    "    1. writer=pd.ExcelWriter()\n",
    "    2. df.to_excel(writer)\n",
    "    3. df.to_excel(writer)\n",
    "    4. writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cac6d",
   "metadata": {},
   "source": [
    "## Join Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28950a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. append:\n",
    "    df1.append(df2,ignore_index=True)\n",
    "2. concat:\n",
    "    pd.concat([df1,df2...],axis=0,join='outer',ignore_index=False,sort=False)\n",
    "    pd.concat(df_list,axis=1,join='inner',ignore_index=False,sort=False) \n",
    "    \n",
    "3. merge:\n",
    "    1. left_df.merge(right_df)\n",
    "    2. pd.merge(l_df,r_df,how='inner',on='col_name',suffixes=('_df1','_df2'))\n",
    "    \n",
    "4. join:\n",
    "    left_df.join(right_df,how='inner',lsuffix='_df1',rsuffix='_df2')\n",
    "    \n",
    "joins>> ['inner','outer','left','right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd032e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
